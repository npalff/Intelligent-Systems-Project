{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd0QD9mNgyVR"
      },
      "source": [
        "# <center>Recognizing Digits using Neural Networks</center>\n",
        "####<center>Academic Year 2020 - 2021</center>\n",
        "#### <center>Group 15</center>\n",
        "\n",
        "<center>\n",
        "Jo√£o Vitor VARGAS SOARES <br>\n",
        "Nicolau PEREIRA ALFF\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "This is a project exercise for the subject Intelligent Systems: Recognition and Reasoning at ENSIMAG.\n",
        "\n",
        "We will program a neural network in Python 3 and Keras to recognize digits in the MNIST (Modified National Institute of Standards and Technology) dataset.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGC4AjRlnjjB"
      },
      "source": [
        "[Link for the report](https://docs.google.com/document/d/1Bdze_nderfIXkC_ewwc2OzQ3IVtiaJ2Qy45FCWcxR6Q/edit?usp=sharing)\n",
        "\n",
        "[Link for the given example](https://colab.research.google.com/drive/1MSoUL8oucsJOT4CaEcELDJ67YrEBjCBi?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq00F-QJd8tB"
      },
      "source": [
        "#Fully connected multi-layer network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3JkbcQSpMPB"
      },
      "source": [
        "#Import all libraries we will need\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "def prepareData():\n",
        "    # Upload dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    num_classes = 10 # 10 numbers, from 0 to 9\n",
        "\n",
        "    # Concatenate training and testing sets to redivide later\n",
        "    x = np.array(np.concatenate((x_train, x_test)))\n",
        "    y = np.array(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    # Reshaping x from (70000, 28, 28) to (70000, 784)\n",
        "    x = x.reshape(x.shape[0], 784)\n",
        "\n",
        "    # Dividing total set into test set (10%), training set (80%) and validation set (10%)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1 , random_state=42)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1/9 , random_state=42)\n",
        "\n",
        "    # Saving class vector for further use\n",
        "    y_test_classes = y_test\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    return x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes\n",
        "\n",
        "def fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizer):\n",
        "    # Initializing model\n",
        "    model = Sequential()\n",
        "\n",
        "    #Adding input layer with first_units as the number of neurons, input shape (784,) and activation\n",
        "    model.add(Dense(units=layers[0][\"units\"], input_shape=(x_train.shape[1],), activation=layers[0][\"activation\"]))\n",
        "\n",
        "    # Using dropout to avoid overfitting\n",
        "    model.add(Dropout(layers[0][\"dropout\"]))\n",
        "\n",
        "    # Adding hidden layers\n",
        "    for layer in layers[1:-1]:\n",
        "        model.add(Dense(units=layer[\"units\"], activation = layer[\"activation\"]))\n",
        "        model.add(Dropout(layer[\"dropout\"]))\n",
        "\n",
        "    # Adding output layer\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "\n",
        "    # Early stop when accuracy diverges\n",
        "    es = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=8,\n",
        "                        min_delta=0.001,\n",
        "                        mode='max')\n",
        "\n",
        "    # model fit with maximum of 500 epochs\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=128, epochs=500,\n",
        "            verbose=2,\n",
        "            validation_data=(x_valid, y_valid),\n",
        "            callbacks=es)\n",
        "    return model, history\n",
        "\n",
        "# This function makes the predictions and metrics for a determined model\n",
        "def predictionsAndMetrics(model, x_test, y_test_classes):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    y_prediction_probs = model.predict(x_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    y_prediction_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test_classes, y_prediction_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_test_classes, y_prediction_probs, multi_class='ovr')\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "# This function varies the number of hidden layers from 1 to 5 for comparison\n",
        "def varyingLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    for i in range(5):\n",
        "        model, history = fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        layers = np.append(layers, [{\"units\": 512, \"activation\": 'relu', \"dropout\": 0.2}])\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        " # This function varies the number of units from 32 to 512 for comparison\n",
        "def varyingUnits(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    for i in range(5):\n",
        "        model, history = fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        layers[0][\"units\"] = layers[0][\"units\"] * 2\n",
        "        layers[1][\"units\"] = layers[1][\"units\"] * 2\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "# This function varies the learning rate in the optimizer function Adam from 1 to 0.00001 for comparison\n",
        "def varyingLearningRate(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    lr = 1\n",
        "    for i in range(5):\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "        model, history = fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        lr = lr/10\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "# This function varies the type of optimizer used in the model compilation for comparison\n",
        "def varyingOptimizer(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    lr = 1\n",
        "    optimizers = np.array(['rmsprop', 'adam', 'sgd', 'adadelta', 'adamax'])\n",
        "    for i in range(5):\n",
        "        model, history = fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizers[i])\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        lr = lr/10\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "# This function varies the percentage of dropout from 0.1 to 0.5 for comparison\n",
        "def varyingDropout(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    dropout = 0.1\n",
        "    for i in range(5):\n",
        "        layers[0][\"dropout\"] = dropout\n",
        "        layers[1][\"dropout\"] = dropout\n",
        "        model, history = fullyConnectedMultiLayerNetwork(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        dropout += 0.1\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes = prepareData()\n",
        "layers = np.array([\n",
        "                    {\"units\": 32, \"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    {\"units\": 32, \"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    ])\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "metrics_layers = varyingLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "metrics_units = varyingUnits(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "metrics_learningRate = varyingLearningRate(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "metrics_optimizer = varyingOptimizer(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers)\n",
        "metrics_dropout = varyingDropout(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "\n",
        "print(metrics_layers)\n",
        "print(metrics_units)\n",
        "print(metrics_learningRate)\n",
        "print(metrics_optimizer)\n",
        "print(metrics_dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B7oLLnoeRRO"
      },
      "source": [
        "Notes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhUMzbwo9mt6"
      },
      "source": [
        "#CNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbnUd2Se1HDo"
      },
      "source": [
        "# Libraries imports\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from glob import glob\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model/Data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28,28,1)\n",
        "validation_ratio = 0.1\n",
        "\n",
        "def prepareData():\n",
        "    # Upload dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    num_classes = 10 # 10 numbers, from 0 to 9\n",
        "\n",
        "    # Concatenate training and testing sets to redivide later\n",
        "    x = np.array(np.concatenate((x_train, x_test)))\n",
        "    y = np.array(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    x = np.expand_dims(x, -1)\n",
        "    print(\"x shape:\", x.shape)\n",
        "    print(x.shape[0], \"samples\")\n",
        "\n",
        "\n",
        "    # Dividing total set into test set (10%), training set (80%) and validation set (10%)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1 , random_state=42)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1/9 , random_state=42)\n",
        "\n",
        "    # Saving class vector for further use\n",
        "    y_test_classes = y_test\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(x_train.shape[0], \"train samples\")\n",
        "    print(x_test.shape[0], \"test samples\")\n",
        "    print(x_valid.shape[0], \"validation samples\")\n",
        "\n",
        "    return x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes\n",
        "\n",
        "def CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer):\n",
        "    # Initializing model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "\n",
        "    # Adding hidden layers\n",
        "    for layer in layers[1:-1]:\n",
        "        model.add(Conv2D(layer[\"filters\"],layer[\"kernelSize\"], activation = layer[\"activation\"], kernel_initializer='he_uniform'))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "    # Adding output layer\n",
        "    model.add(Flatten())\n",
        "    # Using dropout to avoid overfitting\n",
        "    model.add(Dropout(layers[0][\"dropout\"]))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "    #model.summary()\n",
        "\n",
        "    # Early stop when accuracy diverges\n",
        "    es = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=8,\n",
        "                        min_delta=0.001,\n",
        "                        mode='max')\n",
        "\n",
        "    # model fit with maximum of 500 epochs\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=128, epochs=500,\n",
        "            verbose=2,\n",
        "            validation_data=(x_valid, y_valid),\n",
        "            callbacks=es)\n",
        "\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# This function makes the predictions and metrics for a determined model\n",
        "def predictionsAndMetrics(model, x_test, y_test_classes):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    y_prediction_probs = model.predict(x_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    y_prediction_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test_classes, y_prediction_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_test_classes, y_prediction_probs, multi_class='ovr')\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "def baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    print(\"Baseline\")\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "    accuracy, precision, recall, f1, auc = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "    layers = np.append(layers, [{\"filters\": 64,\"kernelSize\": (3,3) ,\"activation\": 'relu', \"dropout\": 0.2}])\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "# This function varies the number of Convolutional layers from 3 to 7 for comparison\n",
        "def varyingConvLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    print(\"Varying Number of Convolutional Layers\")\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    for i in range(5):\n",
        "        model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        layers = np.append(layers, [{\"filters\": 64,\"kernelSize\": (2,2) ,\"activation\": 'relu', \"dropout\": 0.2}])\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "# This function varies the number of filters per layers\n",
        "def varyingFiltersLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    print(\"Varying Number of Filters per Layer\")\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    for i in range(5):\n",
        "        model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        layers = np.append(layers,[{\"filters\": 8*(2**i),\"kernelSize\": (3,3) ,\"activation\": 'relu', \"dropout\": 0.2}])\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes = prepareData()\n",
        "\n",
        "layers = np.array([\n",
        "                    {\"filters\": 64,\"kernelSize\": (3,3) ,\"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    ])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "metrics_Baseline = baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "#metrics_convolutional_layers = varyingConvLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "#metrics_filters_per_layer = varyingFiltersLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "\n",
        "\n",
        "print(metrics_Baseline)\n",
        "#print(metrics_convolutional_layers)\n",
        "#print(metrics_filters_per_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nkqCE74p0yo"
      },
      "source": [
        "## Different Types and Sizes of Pooling Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR-3QMm7p8Tx",
        "outputId": "e8309eb2-371b-4642-a177-47b9e475a2cb"
      },
      "source": [
        "# Libraries imports\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from glob import glob\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model/Data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28,28,1)\n",
        "validation_ratio = 0.1\n",
        "\n",
        "def prepareData():\n",
        "    # Upload dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    num_classes = 10 # 10 numbers, from 0 to 9\n",
        "\n",
        "    # Concatenate training and testing sets to redivide later\n",
        "    x = np.array(np.concatenate((x_train, x_test)))\n",
        "    y = np.array(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    x = np.expand_dims(x, -1)\n",
        "    print(\"x shape:\", x.shape)\n",
        "    print(x.shape[0], \"samples\")\n",
        "\n",
        "\n",
        "    # Dividing total set into test set (10%), training set (80%) and validation set (10%)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1 , random_state=42)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1/9 , random_state=42)\n",
        "\n",
        "    # Saving class vector for further use\n",
        "    y_test_classes = y_test\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(x_train.shape[0], \"train samples\")\n",
        "    print(x_test.shape[0], \"test samples\")\n",
        "    print(x_valid.shape[0], \"validation samples\")\n",
        "\n",
        "    return x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes\n",
        "\n",
        "def CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer):\n",
        "\n",
        "#Different Types and sizes of Pooling Layers\n",
        "#model.add(MaxPooling2D((2,2))) --- Baseline\n",
        "#model.add(MaxPooling2D((4,4)))\n",
        "#model.add(AveragePooling2D((2,2)))\n",
        "#model.add(AveragePooling2D((1,1)))\n",
        "#model.add(MaxPooling2D(2,1))\n",
        "\n",
        "    # Initializing model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(2,1))\n",
        "    model.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D(2,1))\n",
        "    # Using dropout to avoid overfitting\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Adding hidden layers\n",
        "    for layer in layers[1:-1]:\n",
        "        model.add(Conv2D(layer[\"filters\"],layer[\"kernelSize\"], activation = layer[\"activation\"], kernel_initializer='he_uniform'))\n",
        "        model.add(MaxPooling2D(2,1))\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "    # Adding output layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "    model.summary()\n",
        "\n",
        "    # Early stop when accuracy diverges\n",
        "    es = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=8,\n",
        "                        min_delta=0.001,\n",
        "                        mode='max')\n",
        "\n",
        "    # model fit with maximum of 500 epochs\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=128, epochs=500,\n",
        "            verbose=0,\n",
        "            validation_data=(x_valid, y_valid),\n",
        "            callbacks=es)\n",
        "\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# This function makes the predictions and metrics for a determined model\n",
        "def predictionsAndMetrics(model, x_test, y_test_classes):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    y_prediction_probs = model.predict(x_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    y_prediction_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test_classes, y_prediction_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_test_classes, y_prediction_probs, multi_class='ovr')\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "def baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    print(\"Baseline\")\n",
        "    accuracy = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1 = 0\n",
        "    auc = 0\n",
        "    model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "    accuracy, precision, recall, f1, auc = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes = prepareData()\n",
        "\n",
        "layers = np.array([\n",
        "\n",
        "                    ])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "metrics_Baseline = baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "print(metrics_Baseline)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape: (70000, 28, 28, 1)\n",
            "70000 samples\n",
            "56000 train samples\n",
            "7000 test samples\n",
            "7000 validation samples\n",
            "Baseline\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_137 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_121 (MaxPoolin (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_138 (Conv2D)          (None, 23, 23, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_122 (MaxPoolin (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_66 (Flatten)         (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 10)                309770    \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 328,586\n",
            "Trainable params: 328,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8xMtj5k8jMg"
      },
      "source": [
        "## CNN - Different Numbers of filters per Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F2q7v2s8rt7",
        "outputId": "9797783d-e786-454e-cdcb-9318e1dbb547"
      },
      "source": [
        "# Libraries imports\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from glob import glob\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model/Data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28,28,1)\n",
        "validation_ratio = 0.1\n",
        "\n",
        "def prepareData():\n",
        "    # Upload dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    num_classes = 10 # 10 numbers, from 0 to 9\n",
        "\n",
        "    # Concatenate training and testing sets to redivide later\n",
        "    x = np.array(np.concatenate((x_train, x_test)))\n",
        "    y = np.array(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    x = np.expand_dims(x, -1)\n",
        "    print(\"x shape:\", x.shape)\n",
        "    print(x.shape[0], \"samples\")\n",
        "\n",
        "\n",
        "    # Dividing total set into test set (10%), training set (80%) and validation set (10%)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1 , random_state=42)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1/9 , random_state=42)\n",
        "\n",
        "    # Saving class vector for further use\n",
        "    y_test_classes = y_test\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(x_train.shape[0], \"train samples\")\n",
        "    print(x_test.shape[0], \"test samples\")\n",
        "    print(x_valid.shape[0], \"validation samples\")\n",
        "\n",
        "    return x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes\n",
        "\n",
        "def CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer):\n",
        "\n",
        "#Different Numbers of filters per Layer\n",
        "########## First cl  |  Second cl\n",
        "#Baseline     32          64\n",
        "#             16          32\n",
        "#             16          16\n",
        "#             8          16\n",
        "\n",
        "    # Initializing model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(8,(3,3), activation = 'relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D(2,1))\n",
        "    model.add(Conv2D(16, (3,3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D(2,1))\n",
        "    # Using dropout to avoid overfitting\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Adding hidden layers\n",
        "    for layer in layers[1:-1]:\n",
        "        model.add(Conv2D(layer[\"filters\"],layer[\"kernelSize\"], activation = layer[\"activation\"], kernel_initializer='he_uniform'))\n",
        "        model.add(MaxPooling2D(2,1))\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "    # Adding output layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "    model.summary()\n",
        "\n",
        "    # Early stop when accuracy diverges\n",
        "    es = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=8,\n",
        "                        min_delta=0.001,\n",
        "                        mode='max')\n",
        "\n",
        "    # model fit with maximum of 500 epochs\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=128, epochs=500,\n",
        "            verbose=2,\n",
        "            validation_data=(x_valid, y_valid),\n",
        "            callbacks=es)\n",
        "\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# This function makes the predictions and metrics for a determined model\n",
        "def predictionsAndMetrics(model, x_test, y_test_classes):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    y_prediction_probs = model.predict(x_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    y_prediction_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test_classes, y_prediction_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_test_classes, y_prediction_probs, multi_class='ovr')\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "def baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    print(\"Baseline\")\n",
        "    accuracy = 0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1 = 0\n",
        "    auc = 0\n",
        "    model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "    accuracy, precision, recall, f1, auc = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes = prepareData()\n",
        "\n",
        "layers = np.array([\n",
        "\n",
        "                    ])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "metrics_Baseline = baseline(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "print(metrics_Baseline)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape: (70000, 28, 28, 1)\n",
            "70000 samples\n",
            "56000 train samples\n",
            "7000 test samples\n",
            "7000 validation samples\n",
            "Baseline\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 25, 25, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 23, 23, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 7744)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                77450     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 78,698\n",
            "Trainable params: 78,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "438/438 - 41s - loss: 0.3340 - accuracy: 0.9291 - val_loss: 0.0851 - val_accuracy: 0.9707\n",
            "Epoch 2/500\n",
            "438/438 - 40s - loss: 0.1108 - accuracy: 0.9659 - val_loss: 0.0838 - val_accuracy: 0.9736\n",
            "Epoch 3/500\n",
            "438/438 - 40s - loss: 0.0889 - accuracy: 0.9731 - val_loss: 0.0666 - val_accuracy: 0.9794\n",
            "Epoch 4/500\n",
            "438/438 - 40s - loss: 0.0798 - accuracy: 0.9753 - val_loss: 0.0686 - val_accuracy: 0.9796\n",
            "Epoch 5/500\n",
            "438/438 - 40s - loss: 0.0727 - accuracy: 0.9778 - val_loss: 0.0604 - val_accuracy: 0.9806\n",
            "Epoch 6/500\n",
            "438/438 - 40s - loss: 0.0686 - accuracy: 0.9787 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
            "Epoch 7/500\n",
            "438/438 - 40s - loss: 0.0626 - accuracy: 0.9795 - val_loss: 0.0554 - val_accuracy: 0.9844\n",
            "Epoch 8/500\n",
            "438/438 - 40s - loss: 0.0613 - accuracy: 0.9806 - val_loss: 0.0652 - val_accuracy: 0.9813\n",
            "Epoch 9/500\n",
            "438/438 - 40s - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.0619 - val_accuracy: 0.9831\n",
            "Epoch 10/500\n",
            "438/438 - 40s - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.0610 - val_accuracy: 0.9831\n",
            "Epoch 11/500\n",
            "438/438 - 40s - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0726 - val_accuracy: 0.9799\n",
            "Epoch 12/500\n",
            "438/438 - 40s - loss: 0.0567 - accuracy: 0.9826 - val_loss: 0.0571 - val_accuracy: 0.9847\n",
            "Epoch 13/500\n",
            "438/438 - 40s - loss: 0.0513 - accuracy: 0.9839 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 14/500\n",
            "438/438 - 40s - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.0636 - val_accuracy: 0.9849\n",
            "Epoch 15/500\n",
            "438/438 - 40s - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.0658 - val_accuracy: 0.9830\n",
            "Accuracy: 0.978286\n",
            "Precision: 0.978098\n",
            "Recall: 0.978365\n",
            "F1 score: 0.978180\n",
            "ROC AUC: 0.999638\n",
            "{'accuracy': 0.9782857142857143, 'precision': 0.978098025249718, 'recall': 0.9783645525044629, 'f1': 0.9781799936107006, 'auc': 0.9996375273315042}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j0UvUDtppLh"
      },
      "source": [
        "##CNN - Different Fully-connected Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0rWKTenpxaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837635bc-ac01-48cf-ed0c-99ab44d69ff1"
      },
      "source": [
        "# Libraries imports\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from glob import glob\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model/Data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28,28,1)\n",
        "validation_ratio = 0.1\n",
        "\n",
        "def prepareData():\n",
        "    # Upload dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    num_classes = 10 # 10 numbers, from 0 to 9\n",
        "\n",
        "    # Concatenate training and testing sets to redivide later\n",
        "    x = np.array(np.concatenate((x_train, x_test)))\n",
        "    y = np.array(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    x = np.expand_dims(x, -1)\n",
        "    print(\"x shape:\", x.shape)\n",
        "    print(x.shape[0], \"samples\")\n",
        "\n",
        "\n",
        "    # Dividing total set into test set (10%), training set (80%) and validation set (10%)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1 , random_state=42)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1/9 , random_state=42)\n",
        "\n",
        "    # Saving class vector for further use\n",
        "    y_test_classes = y_test\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(x_train.shape[0], \"train samples\")\n",
        "    print(x_test.shape[0], \"test samples\")\n",
        "    print(x_valid.shape[0], \"validation samples\")\n",
        "\n",
        "    return x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes\n",
        "\n",
        "def CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer):\n",
        "    # Initializing model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(2,2), activation = 'relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Conv2D(64, (2,2), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Flatten())\n",
        "    # Using dropout to avoid overfitting\n",
        "    model.add(Dropout(layers[0][\"dropout\"]))\n",
        "\n",
        "    # Adding hidden layers\n",
        "    for layer in layers[1:-1]:\n",
        "        model.add(Dense(units=layer[\"units\"], activation = layer[\"activation\"]))\n",
        "        model.add(Dropout(layer[\"dropout\"]))\n",
        "\n",
        "    # Adding output layer\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "    model.summary()\n",
        "\n",
        "    # Early stop when accuracy diverges\n",
        "    es = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=8,\n",
        "                        min_delta=0.001,\n",
        "                        mode='max')\n",
        "\n",
        "    # model fit with maximum of 500 epochs\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=128, epochs=500,\n",
        "            verbose=0,\n",
        "            validation_data=(x_valid, y_valid),\n",
        "            callbacks=es)\n",
        "\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# This function makes the predictions and metrics for a determined model\n",
        "def predictionsAndMetrics(model, x_test, y_test_classes):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    y_prediction_probs = model.predict(x_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    y_prediction_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test_classes, y_prediction_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test_classes, y_prediction_classes, average='macro')\n",
        "    print('F1 score: %f' % f1)\n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_test_classes, y_prediction_probs, multi_class='ovr')\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "# This function varies the number of hidden layers from 1 to 5 for comparison\n",
        "def varyingFConnLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer):\n",
        "    accuracy = np.zeros(5)\n",
        "    precision = np.zeros(5)\n",
        "    recall = np.zeros(5)\n",
        "    f1 = np.zeros(5)\n",
        "    auc = np.zeros(5)\n",
        "    for i in range(5):\n",
        "        model, history = CNNModel(layers, x_train, y_train, x_valid, y_valid, optimizer)\n",
        "        accuracy[i], precision[i], recall[i], f1[i], auc[i] = predictionsAndMetrics(model, x_test, y_test_classes)\n",
        "        layers = np.append(layers, [{\"units\": 32, \"activation\": 'relu', \"dropout\": 0.2}])\n",
        "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "    return metrics\n",
        "\n",
        "x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes = prepareData()\n",
        "\n",
        "layers = np.array([\n",
        "                    {\"filters\": 32,\"kernelSize\": (2,2) ,\"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    ])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "layers = np.array([\n",
        "                    {\"units\": 32, \"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    {\"units\": 32, \"activation\": 'relu', \"dropout\": 0.2},\n",
        "                    ])\n",
        "\n",
        "\n",
        "metrics_fullyConnected_layers = varyingFConnLayers(x_test, x_train, x_valid, y_test, y_train, y_valid, y_test_classes, layers, optimizer)\n",
        "\n",
        "print(metrics_fullyConnected_layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape: (70000, 28, 28, 1)\n",
            "70000 samples\n",
            "56000 train samples\n",
            "7000 test samples\n",
            "7000 validation samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                23050     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 31,466\n",
            "Trainable params: 31,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.982286\n",
            "Precision: 0.982124\n",
            "Recall: 0.982222\n",
            "F1 score: 0.982149\n",
            "ROC AUC: 0.999703\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                73760     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 82,506\n",
            "Trainable params: 82,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.968143\n",
            "Precision: 0.967937\n",
            "Recall: 0.968127\n",
            "F1 score: 0.967920\n",
            "ROC AUC: 0.999098\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                73760     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 83,562\n",
            "Trainable params: 83,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.957714\n",
            "Precision: 0.957432\n",
            "Recall: 0.958296\n",
            "F1 score: 0.957620\n",
            "ROC AUC: 0.998179\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 12, 12, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                73760     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 84,618\n",
            "Trainable params: 84,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 0.114286\n",
            "Precision: 0.011429\n",
            "Recall: 0.100000\n",
            "F1 score: 0.020513\n",
            "ROC AUC: 0.500000\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 27, 27, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                73760     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 85,674\n",
            "Trainable params: 85,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.888143\n",
            "Precision: 0.889485\n",
            "Recall: 0.887476\n",
            "F1 score: 0.887712\n",
            "ROC AUC: 0.989106\n",
            "{'accuracy': array([0.98228571, 0.96814286, 0.95771429, 0.11428571, 0.88814286]), 'precision': array([0.9821239 , 0.96793727, 0.95743178, 0.01142857, 0.88948489]), 'recall': array([0.98222242, 0.96812703, 0.95829644, 0.1       , 0.88747591]), 'f1': array([0.9821495 , 0.96791965, 0.95762021, 0.02051282, 0.88771156]), 'auc': array([0.99970345, 0.99909762, 0.99817873, 0.5       , 0.9891062 ])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvuw8gWKeWTr"
      },
      "source": [
        "Notes:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0EXegIjdhtX"
      },
      "source": [
        "#References\n",
        "\n",
        "* [How to Develop a CNN for MNIST\n",
        "Handwritten Digit Classification\n",
        "](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/)\n",
        "* [Understand the Impact of Learning Rate on Neural Network Performance\n",
        "](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/)\n",
        "* [How Do Convolutional Layers Work in Deep Learning Neural Networks?\n",
        "](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)\n",
        "* [A Gentle Introduction to k-fold Cross-Validation\n",
        "](https://machinelearningmastery.com/k-fold-cross-validation/)\n",
        "* [MNIST Handwritten Digit Recognition in Keras](https://nextjournal.com/gkoehler/digit-recognition-with-keras)\n",
        "* [Keras for Beginners: Building Your First Neural Network\n",
        "](https://victorzhou.com/blog/keras-neural-network-tutorial/)\n",
        "* [MNIST - Deep Neural Network with Keras\n",
        "](https://www.kaggle.com/prashant111/mnist-deep-neural-network-with-keras)\n",
        "* [Introduction to Multilayer Neural Networks with TensorFlow‚Äôs Keras API\n",
        "](https://towardsdatascience.com/introduction-to-multilayer-neural-networks-with-tensorflows-keras-api-abf4f813959)\n",
        "\n"
      ]
    }
  ]
}